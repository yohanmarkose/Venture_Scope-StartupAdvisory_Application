{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da1caaf8",
   "metadata": {},
   "source": [
    "### **Snowflake connection testing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "696b2bb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\yohan\\anaconda3\\envs\\final_project_2\\Lib\\site-packages\\snowflake\\connector\\options.py:108: UserWarning: You have an incompatible version of 'pyarrow' installed (19.0.1), please install a version that adheres to: 'pyarrow<19.0.0; extra == \"pandas\"'\n",
      "  warn_incompatible_dep(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import snowflake.connector\n",
    "import yfinance as yf\n",
    "import numpy as np\n",
    "import datetime\n",
    "import time\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "conn_params = {\n",
    "    'user': os.getenv('SNOWFLAKE_USER'),\n",
    "    'password': os.getenv('SNOWFLAKE_PASSWORD'),\n",
    "    'account': os.getenv('SNOWFLAKE_ACCOUNT'),\n",
    "    'warehouse': os.getenv('SNOWFLAKE_WAREHOUSE'),\n",
    "    'database': os.getenv('SNOWFLAKE_DATABASE'),\n",
    "    'schema': os.getenv('SNOWFLAKE_SCHEMA'),\n",
    "    'role': os.getenv('SNOWFLAKE_ROLE')\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f8033aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def connect_to_snowflake(params):\n",
    "    try:\n",
    "        conn = snowflake.connector.connect(\n",
    "            user=params['user'],\n",
    "            password=params['password'],\n",
    "            account=params['account'],\n",
    "            warehouse=params['warehouse'],\n",
    "            database=params['database'],\n",
    "            schema=params['schema'],\n",
    "            role=params['role']  # Specify the role if needed\n",
    "        )\n",
    "        print(\"Connected to Snowflake successfully!\")\n",
    "        return conn\n",
    "    except Exception as e:\n",
    "        print(f\"Error connecting to Snowflake: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ebde697",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to Snowflake successfully!\n"
     ]
    }
   ],
   "source": [
    "conn = connect_to_snowflake(conn_params)\n",
    "\n",
    "if conn is None:\n",
    "    print(\"Failed to connect to Snowflake. Exiting.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28a52335",
   "metadata": {},
   "source": [
    "### **Checking data for all industries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03f72437",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_industry_with_no_data():\n",
    "    conn = connect_to_snowflake(conn_params)\n",
    "    if conn is None:\n",
    "        return None\n",
    "    try:\n",
    "        query = \"\"\"\n",
    "        SELECT\n",
    "        INDUSTRY\n",
    "        FROM OPPORTUNITY_ANALYSIS.MARKET_ANALYSIS.ENHANCED_COMPANIES\n",
    "        GROUP BY INDUSTRY\n",
    "        HAVING\n",
    "        COUNT(DISTINCT SIZE_CATAGORY) < 3;\n",
    "        \"\"\"\n",
    "        \n",
    "        df = pd.read_sql(query, conn)\n",
    "        conn.close()\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        if conn:\n",
    "            conn.close()\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c9861db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to Snowflake successfully!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yohan\\AppData\\Local\\Temp\\ipykernel_20648\\2461738291.py:15: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(query, conn)\n"
     ]
    }
   ],
   "source": [
    "df = get_industry_with_no_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2ab5389",
   "metadata": {},
   "source": [
    "**The below empty data frame means that all industries have data for all size categories**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fcfc8b8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>INDUSTRY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [INDUSTRY]\n",
       "Index: []"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02bfbb7b",
   "metadata": {},
   "source": [
    "## Table updation with YFINANCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d19501db",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def create_table_in_snowflake(conn, table_name=\"LARGE_COMPANY_DATA_FINAL\", schema=\"OPPORTUNITY_ANALYSIS.MARKET_ANALYSIS\"):\n",
    "    create_query = f\"\"\"\n",
    "    CREATE OR REPLACE TABLE {schema}.{table_name} (\n",
    "        ID VARCHAR,\n",
    "        COMPANY_NAME VARCHAR,\n",
    "        INDUSTRY VARCHAR,\n",
    "        SIZE VARCHAR,\n",
    "        FOUNDED NUMBER,\n",
    "        REGION VARCHAR,\n",
    "        COUNTRY VARCHAR,\n",
    "        LOCALITY VARCHAR,\n",
    "        WEBSITE VARCHAR,\n",
    "        LINKEDIN_URL VARCHAR,\n",
    "        COMPANY_AGE NUMBER,\n",
    "        SIZE_CATAGORY VARCHAR,\n",
    "        PERFORMANCE_CATEGORY VARCHAR,\n",
    "        PERFORMANCE_SCORE FLOAT,\n",
    "        T_SYMBOL VARCHAR,\n",
    "        TICKER VARCHAR,\n",
    "        CURRENT_PRICE FLOAT,\n",
    "        MARKET_CAP NUMBER,\n",
    "        YEARLY_RETURN NUMBER,\n",
    "        VOLATILITY VARCHAR\n",
    "    );\n",
    "    \"\"\"\n",
    "    try:\n",
    "        cursor = conn.cursor()\n",
    "        cursor.execute(create_query)\n",
    "        print(f\"Table {schema}.{table_name} created or replaced.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error creating table: {e}\")\n",
    "    finally:\n",
    "        cursor.close()\n",
    "\n",
    "def save_df_to_snowflake(df, table_name=\"LARGE_COMPANY_DATA_FINAL\", database=\"OPPORTUNITY_ANALYSIS\", schema=\"MARKET_ANALYSIS\"):\n",
    "    conn = connect_to_snowflake(conn_params)\n",
    "    if conn is None:\n",
    "        print(\"❌ Could not connect to Snowflake.\")\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        conn.cursor().execute(f\"USE DATABASE {database}\")\n",
    "        conn.cursor().execute(f\"USE SCHEMA {schema}\")\n",
    "\n",
    "        df.columns = [col.upper() for col in df.columns]\n",
    "\n",
    "        create_table_in_snowflake(conn, table_name, f\"{database}.{schema}\")\n",
    "\n",
    "        # Write data using uppercase column names\n",
    "        success, nchunks, nrows, _ = write_pandas(conn, df, table_name=table_name, schema=schema)\n",
    "\n",
    "        if success:\n",
    "            print(f\"Successfully inserted {nrows} rows into {database}.{schema}.{table_name}\")\n",
    "        else:\n",
    "            print(f\"Failed to write DataFrame to Snowflake\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error writing DataFrame to Snowflake: {e}\")\n",
    "    finally:\n",
    "        conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90b3bc76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_company_data():\n",
    "    conn = connect_to_snowflake(conn_params)\n",
    "    if conn is None:\n",
    "        return None\n",
    "    try:\n",
    "        query = \"\"\"\n",
    "        SELECT * FROM LARGE_COMPANIES_WITH_TICKER\n",
    "        WHERE T_SYMBOL IS NOT NULL\n",
    "        \"\"\"\n",
    "        \n",
    "        df = pd.read_sql(query, conn)\n",
    "        conn.close()\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        if conn:\n",
    "            conn.close()\n",
    "        return None\n",
    "\n",
    "def get_yfinance_metrics(ticker_list):\n",
    "    # Filter out None values\n",
    "    ticker_list = [t for t in ticker_list if t]\n",
    "    \n",
    "    if not ticker_list:\n",
    "        return pd.DataFrame()\n",
    "    results = {}\n",
    "    batch_size = 15\n",
    "    for i in range(0, len(ticker_list), batch_size):\n",
    "        batch = ticker_list[i:i+batch_size]\n",
    "        print(f\"Processing batch {i//batch_size + 1}/{(len(ticker_list) + batch_size - 1)//batch_size}\")\n",
    "        \n",
    "        for ticker in batch:\n",
    "            try:\n",
    "                ticker_obj = yf.Ticker(ticker)\n",
    "                info = ticker_obj.info\n",
    "                hist = ticker_obj.history(period=\"1y\")\n",
    "                if len(hist) > 0:\n",
    "                    start_price = hist['Close'].iloc[0]\n",
    "                    current_price = hist['Close'].iloc[-1]\n",
    "                    yearly_return = ((current_price - start_price) / start_price) * 100\n",
    "                    daily_returns = hist['Close'].pct_change().dropna()\n",
    "                    volatility = daily_returns.std() * 100 * np.sqrt(252)  # Annualized\n",
    "                else:\n",
    "                    yearly_return = None\n",
    "                    volatility = None\n",
    "                \n",
    "                # Store the results\n",
    "                results[ticker] = {\n",
    "                    'ticker': ticker,\n",
    "                    'current_price': current_price,\n",
    "                    'market_cap': info.get('marketCap', None),\n",
    "                    'yearly_return': yearly_return,\n",
    "                    'volatility': volatility,\n",
    "                }\n",
    "                time.sleep(0.1)  # To avoid hitting the API too fast\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error processing ticker {ticker}: {e}\")\n",
    "                # Add the ticker to results with None values to maintain the record\n",
    "                results[ticker] = {\n",
    "                    'ticker': ticker,\n",
    "                    'current_price': None,\n",
    "                    'market_cap': None,\n",
    "                    'yearly_return': None,\n",
    "                    'volatility': None\n",
    "                }\n",
    "    \n",
    "    metrics_df = pd.DataFrame.from_dict(results, orient='index')\n",
    "    return metrics_df\n",
    "\n",
    "def enhance_company_data_with_yfinance():\n",
    "    company_df = get_company_data()\n",
    "    \n",
    "    if company_df is None or company_df.empty:\n",
    "        return\n",
    "\n",
    "    ticker_symbols = company_df['T_SYMBOL'].unique().tolist()\n",
    "    \n",
    "    metrics_df = get_yfinance_metrics(ticker_symbols)\n",
    "    \n",
    "    if metrics_df.empty:\n",
    "        print(\"No metrics data retrieved. Exiting.\")\n",
    "        return\n",
    "    \n",
    "    enhanced_df = pd.merge(\n",
    "        company_df,\n",
    "        metrics_df,\n",
    "        left_on='T_SYMBOL',\n",
    "        right_on='ticker',\n",
    "        how='left'\n",
    "    )\n",
    "    enhanced_df = enhanced_df.drop(columns=['ticker'])\n",
    "\n",
    "    \n",
    "    return enhanced_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d5d7193",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to Snowflake successfully!\n",
      "Table OPPORTUNITY_ANALYSIS.MARKET_ANALYSIS.LARGE_COMPANY_DATA_FINAL created or replaced.\n",
      "✅ Successfully inserted 2007 rows into OPPORTUNITY_ANALYSIS.MARKET_ANALYSIS.LARGE_COMPANY_DATA_FINAL\n"
     ]
    }
   ],
   "source": [
    "en_df = enhance_company_data_with_yfinance()\n",
    "save_df_to_snowflake(en_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2814999d",
   "metadata": {},
   "source": [
    "## Ticker Symbol table creation Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9dad9492",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ftplib\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "\n",
    "def fetch_us_listed_tickers():\n",
    "    ftp = ftplib.FTP('ftp.nasdaqtrader.com')\n",
    "    ftp.login()\n",
    "    ftp.encoding = 'utf-8'\n",
    "    ftp.cwd('SymbolDirectory')\n",
    "\n",
    "    files = [\"nasdaqlisted.txt\", \"otherlisted.txt\"]\n",
    "    all_dfs = []\n",
    "\n",
    "    for file in files:\n",
    "        buffer = []\n",
    "        ftp.retrlines(f\"RETR {file}\", buffer.append)\n",
    "        content = \"\\n\".join(buffer)\n",
    "        \n",
    "        df = pd.read_csv(StringIO(content), sep=\"|\")\n",
    "        df = df[:-1]  # remove footer row\n",
    "        all_dfs.append(df)\n",
    "\n",
    "    ftp.quit()\n",
    "\n",
    "    # Combine and return a unified DataFrame with standardized columns\n",
    "    combined_df = pd.concat(all_dfs, ignore_index=True)\n",
    "    combined_df.rename(columns={'Symbol': 'ticker', 'Security Name': 'company_name'}, inplace=True)\n",
    "    return combined_df[['ticker', 'company_name']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f55ca7ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticker</th>\n",
       "      <th>company_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AACB</td>\n",
       "      <td>Artius II Acquisition Inc. - Class A Ordinary ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AACBR</td>\n",
       "      <td>Artius II Acquisition Inc. - Rights</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AACBU</td>\n",
       "      <td>Artius II Acquisition Inc. - Units</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AACG</td>\n",
       "      <td>ATA Creativity Global - American Depositary Sh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AADR</td>\n",
       "      <td>AdvisorShares Dorsey Wright ADR ETF</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ticker                                       company_name\n",
       "0   AACB  Artius II Acquisition Inc. - Class A Ordinary ...\n",
       "1  AACBR                Artius II Acquisition Inc. - Rights\n",
       "2  AACBU                 Artius II Acquisition Inc. - Units\n",
       "3   AACG  ATA Creativity Global - American Depositary Sh...\n",
       "4   AADR                AdvisorShares Dorsey Wright ADR ETF"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tickers_df = fetch_us_listed_tickers()\n",
    "tickers_df = tickers_df.drop_duplicates(subset=['ticker'])\n",
    "tickers_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "939a6b68",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "final_project_2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
